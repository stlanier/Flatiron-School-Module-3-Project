{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn Model Training and Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary classification project––with or without heart disease––with the overall goal of model accuracy. The dataset, [obtained from Kaggle](https://www.kaggle.com/danimal/heartdiseaseensembleclassifier?select=Heart_Disease_Data.csv), consists of 303 observations and [13 features](https://www.kaggle.com/iamkon/ml-models-performance-on-risk-prediction#Complete-attribute-documentation). Of the 303 observation, 160 are without heart disease and the remaining 143 have some degree of heart disease. The study from which the data are drawn distinguishes between not having heart disease (0, in the 'pred_attribute' column) and 4 degrees of having the disease (1, 2, 3, 4). [Experiments with this dataset have concentrated on simply distinguishing between having and not having the disease](https://www.kaggle.com/iamkon/ml-models-performance-on-risk-prediction), and I have done the same here.\n",
    "\n",
    "The dataset is already fairly clean, which gave me an opportunity to spend more time comparing the performance of a variety of models––a logistic regression model, SVCs, a KNN model, decision trees and Random Forests, and AdaBoost and XGBoost––as well as to try putting together an ensemble of my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pydotplus\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/preprocessed/X_train.pkl', 'rb') as fp:\n",
    "    X_train = pickle.load(fp)\n",
    "    \n",
    "with open('../data/preprocessed/X_test.pkl', 'rb') as fp:\n",
    "    X_test = pickle.load(fp)\n",
    "    \n",
    "with open('../data/preprocessed/y_train.pkl', 'rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "    \n",
    "with open('../data/preprocessed/y_test.pkl', 'rb') as fp:\n",
    "    y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models for Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:\n",
      "LogReg    0.885714\n",
      "RF        0.857143\n",
      "SVC       0.857143\n",
      "KNN       0.828571\n",
      "XGB       0.800000\n",
      "Ada       0.771429\n",
      "DT        0.771429\n",
      "dtype: float64\n",
      "\n",
      "Accuracy:\n",
      "LogReg    0.853333\n",
      "RF        0.840000\n",
      "KNN       0.840000\n",
      "SVC       0.813333\n",
      "XGB       0.800000\n",
      "Ada       0.746667\n",
      "DT        0.746667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "baseline_classifiers = {'LogReg': LogisticRegressionCV(random_state=42),\n",
    "                        'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "                        'SVC': SVC(gamma='auto', random_state=42),\n",
    "                        'DT': DecisionTreeClassifier(random_state=42),\n",
    "                        'RF': RandomForestClassifier(random_state=42),\n",
    "                        'Ada': AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42), \n",
    "                        'XGB': XGBClassifier(random_state=42)}\n",
    "\n",
    "# baseline = {}\n",
    "# for clf in baseline_classifiers:\n",
    "#     name = clf\n",
    "#     clf = baseline_classifiers[clf]\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     preds = clf.predict(X_test)\n",
    "#     acc = accuracy_score(y_test, preds)\n",
    "#     baseline[name] = acc\n",
    "# print(pd.Series(baseline).sort_values(ascending=False))\n",
    "\n",
    "baseline_acc = {}\n",
    "baseline_recall = {}\n",
    "for clf in baseline_classifiers:\n",
    "    name = clf\n",
    "    clf = baseline_classifiers[clf]\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    baseline_acc[name] = acc\n",
    "    baseline_recall[name] = recall\n",
    "    \n",
    "print('Recall:')\n",
    "print(pd.Series(baseline_recall).sort_values(ascending=False))\n",
    "print('')\n",
    "print('Accuracy:')\n",
    "print(pd.Series(baseline_acc).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86        40\n",
      "           1       0.82      0.89      0.85        35\n",
      "\n",
      "    accuracy                           0.85        75\n",
      "   macro avg       0.85      0.86      0.85        75\n",
      "weighted avg       0.86      0.85      0.85        75\n",
      "\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        40\n",
      "           1       0.83      0.83      0.83        35\n",
      "\n",
      "    accuracy                           0.84        75\n",
      "   macro avg       0.84      0.84      0.84        75\n",
      "weighted avg       0.84      0.84      0.84        75\n",
      "\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82        40\n",
      "           1       0.77      0.86      0.81        35\n",
      "\n",
      "    accuracy                           0.81        75\n",
      "   macro avg       0.82      0.82      0.81        75\n",
      "weighted avg       0.82      0.81      0.81        75\n",
      "\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75        40\n",
      "           1       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.75        75\n",
      "   macro avg       0.75      0.75      0.75        75\n",
      "weighted avg       0.75      0.75      0.75        75\n",
      "\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85        40\n",
      "           1       0.81      0.86      0.83        35\n",
      "\n",
      "    accuracy                           0.84        75\n",
      "   macro avg       0.84      0.84      0.84        75\n",
      "weighted avg       0.84      0.84      0.84        75\n",
      "\n",
      "\n",
      "Ada\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75        40\n",
      "           1       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.75        75\n",
      "   macro avg       0.75      0.75      0.75        75\n",
      "weighted avg       0.75      0.75      0.75        75\n",
      "\n",
      "\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        40\n",
      "           1       0.78      0.80      0.79        35\n",
      "\n",
      "    accuracy                           0.80        75\n",
      "   macro avg       0.80      0.80      0.80        75\n",
      "weighted avg       0.80      0.80      0.80        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in baseline_classifiers:\n",
    "    print(f'\\n{clf}')\n",
    "    print(classification_report(y_test, baseline_classifiers[clf].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most models are seeing a lot of improvement––all models are up on recall score; the KNN model's accuracy increased from 59% to 84%; the SVC's accuracy incrased from 55% to 81%––with the exception of dear XGBoost, which saw a 4% decrease in accuracy. I'll use these models as my baseline for comparing models with finetuned hyperparameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) in my baseline model as opposed to LogisticRegression, which is probably why it performed so well out of the box, so it's already pretty well tuned. I start with the KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "best_models['lr'] = baseline_classifiers['LogReg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7781818181818182\n",
      "Test Recall: 0.8285714285714286\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.84\n",
      "{'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 100)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2, 3],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(clf_knn, param_grid, scoring='recall', cv=10)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "\n",
    "test_recalls = {}\n",
    "test_recalls['KNN'] = recall_score(y_test, gs_knn.predict(X_test))\n",
    "\n",
    "test_accuracies = {}\n",
    "test_accuracies['KNN'] = accuracy_score(y_test, gs_knn.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_knn.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"KNN\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_knn.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"KNN\"]}')\n",
    "print(gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['knn']=gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.749090909090909\n",
      "Test Recall: 0.8857142857142857\n",
      "Train Accuracy: 0.8198198198198198\n",
      "Test Accuracy: 0.8533333333333334\n",
      "{'C': 0.7000000000000001, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "clf_svcl = SVC(random_state=42, probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['linear'], \n",
    "    'C': np.linspace(.1, 1, 10), \n",
    "    'gamma': ['scale', 'auto'], \n",
    "}\n",
    "gs_svcl = GridSearchCV(clf_svcl, param_grid, scoring='recall', cv=10)\n",
    "gs_svcl.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['Linear SVC'] = recall_score(y_test, gs_svcl.predict(X_test))\n",
    "test_accuracies['Linear SVC'] = accuracy_score(y_test, gs_svcl.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_svcl.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"Linear SVC\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_svcl.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"Linear SVC\"]}')\n",
    "print(gs_svcl.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['svcl']=gs_svcl.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy is quite a bit higher than train accuracy, which is a good sign the model isn't overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7290909090909091\n",
      "Test Recall: 0.8571428571428571\n",
      "Train Accuracy: 0.8288288288288288\n",
      "Test Accuracy: 0.8133333333333334\n",
      "{'C': 0.30000000000000004, 'coef0': 0.7000000000000001, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "clf_svcp = SVC(random_state=42, probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['poly'], \n",
    "    'degree': list(range(2, 6)), \n",
    "    'coef0': np.linspace(.1, 1, 10), \n",
    "    'C': np.linspace(.1, 1, 10), \n",
    "    'gamma': ['scale', 'auto'], \n",
    "}\n",
    "gs_svcp = GridSearchCV(clf_svcp, param_grid, scoring='recall', cv=10)\n",
    "gs_svcp.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['Polynomial SVC'] = recall_score(y_test, gs_svcp.predict(X_test))\n",
    "test_accuracies['Polynomial SVC'] = accuracy_score(y_test, gs_svcp.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_svcp.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"Polynomial SVC\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_svcp.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"Polynomial SVC\"]}')\n",
    "print(gs_svcp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['svcp']=gs_svcp.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7181818181818181\n",
      "Test Recall: 0.8571428571428571\n",
      "Train Accuracy: 0.8243243243243243\n",
      "Test Accuracy: 0.88\n",
      "{'C': 0.07, 'coef0': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "clf_svcs = SVC(random_state=42, probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['sigmoid'],\n",
    "    'coef0': np.linspace(1, 50, 10), \n",
    "    'C': np.linspace(.01, .1, 10), \n",
    "    'gamma': ['scale', 'auto'], \n",
    "}\n",
    "gs_svcs = GridSearchCV(clf_svcs, param_grid, scoring='recall', cv=10)\n",
    "gs_svcs.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['Sigmoid SVC'] = recall_score(y_test, gs_svcs.predict(X_test))\n",
    "test_accuracies['Sigmoid SVC'] = accuracy_score(y_test, gs_svcs.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_svcs.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"Sigmoid SVC\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_svcs.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"Sigmoid SVC\"]}')\n",
    "print(gs_svcs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['svcs']=gs_svcs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the linear SVC, the sigmoid SVC seems to be excelling on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (Radial Basis Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7281818181818182\n",
      "Test Recall: 0.8857142857142857\n",
      "Train Accuracy: 0.8378378378378378\n",
      "Test Accuracy: 0.8266666666666667\n",
      "{'C': 0.1, 'coef0': 0.001, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf_svcrbf = SVC(random_state=42, probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['rbf'],\n",
    "    'coef0': np.linspace(.001, .01, 10), \n",
    "    'C': np.linspace(.01, .1, 10), \n",
    "    'gamma': ['scale', 'auto'], \n",
    "}\n",
    "gs_svcrbf = GridSearchCV(clf_svcrbf, param_grid, scoring='recall', cv=10)\n",
    "gs_svcrbf.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['RBF SVC'] = recall_score(y_test, gs_svcrbf.predict(X_test))\n",
    "test_accuracies['RBF SVC'] = accuracy_score(y_test, gs_svcrbf.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_svcrbf.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"RBF SVC\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_svcrbf.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"RBF SVC\"]}')\n",
    "print(gs_svcrbf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['svcrbf']=gs_svcrbf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7672727272727273\n",
      "Test Recall: 0.8571428571428571\n",
      "Train Accuracy: 0.8558558558558559\n",
      "Test Accuracy: 0.8533333333333334\n",
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 3, 5, 7, 9, 11, 13, 15], \n",
    "    'min_samples_split': [10, 20, 30, 40, 50, 60], \n",
    "    'min_samples_leaf': [5, 10, 15, 20, 25, 30, 35, 40],\n",
    "}\n",
    "gs_dt = GridSearchCV(clf_dt, param_grid, scoring='recall', cv=10)\n",
    "gs_dt.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['Decision Tree'] = recall_score(y_test, gs_dt.predict(X_test))\n",
    "test_accuracies['Decision Tree'] = accuracy_score(y_test, gs_dt.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_dt.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"Decision Tree\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_dt.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"Decision Tree\"]}')\n",
    "print(gs_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['dt']=gs_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsed this code to produce a .png file with visualization of decision tree.\\nCommented out now so as not to produce multiple files.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Used this code to produce a .png file with visualization of decision tree.\n",
    "Commented out now so as not to produce multiple files.\n",
    "'''\n",
    "\n",
    "# dot_data = tree.export_graphviz(gs_dt.best_estimator_,\n",
    "#                                 feature_names=X_train.columns,\n",
    "#                                 out_file=None,\n",
    "#                                 filled=True,\n",
    "#                                 rounded=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# colors = ('turquoise', 'orange')\n",
    "# edges = collections.defaultdict(list)\n",
    "\n",
    "# for edge in graph.get_edge_list():\n",
    "#     edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "# for edge in edges:\n",
    "#     edges[edge].sort()    \n",
    "#     for i in range(2):\n",
    "#         dest = graph.get_node(str(edges[edge][i]))[0]\n",
    "#         dest.set_fillcolor(colors[i])\n",
    "\n",
    "# graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7647058823529411\n",
      "Test Recall: 0.8571428571428571\n",
      "Train Accuracy: 0.8288288288288288\n",
      "Test Accuracy: 0.84\n",
      "{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 40, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 576 out of 576 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 500, 1000], \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 3, 7, 20], \n",
    "    'min_samples_split': [10, 40, 100], \n",
    "    'min_samples_leaf': [10, 100],\n",
    "}\n",
    "gs_rf = GridSearchCV(clf_rf, param_grid, verbose=1, scoring='recall', cv=3)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['Random Forest'] = recall_score(y_test, gs_rf.predict(X_test))\n",
    "test_accuracies['Random Forest'] = accuracy_score(y_test, gs_rf.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_rf.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"Random Forest\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_rf.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"Random Forest\"]}')\n",
    "print(gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['rf']=gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7847619047619048\n",
      "Test Recall: 0.8571428571428571\n",
      "Train Accuracy: 0.8558558558558559\n",
      "Test Accuracy: 0.84\n",
      "{'base_estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.1, 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "clf_ab = AdaBoostClassifier(algorithm='SAMME.R', random_state=42)\n",
    "param_grid = {\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), LogisticRegression(solver='lbfgs', multi_class='auto')], \n",
    "    'n_estimators': [10, 30, 50, 1000], \n",
    "    'learning_rate': [.0001, .001, .01, .1]\n",
    "}\n",
    "gs_ab = GridSearchCV(clf_ab, param_grid, scoring='recall', cv=5)\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "test_recalls['AdaBoost'] = recall_score(y_test, gs_ab.predict(X_test))\n",
    "test_accuracies['AdaBoost'] = accuracy_score(y_test, gs_ab.predict(X_test))\n",
    "\n",
    "print(f'Train Recall: {gs_ab.best_score_}')\n",
    "print(f'Test Recall: {test_recalls[\"AdaBoost\"]}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_ab.predict(X_train))}')\n",
    "print(f'Test Accuracy: {test_accuracies[\"AdaBoost\"]}')\n",
    "print(gs_ab.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models['ab']=gs_ab.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nXGB removed for the time being until I can figure out what's changed with the newest updates.\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "XGB removed for the time being until I can figure out what's changed with the newest updates.\n",
    "'''\n",
    "\n",
    "# clf_xgb = XGBClassifier(random_state=42, probability=True)\n",
    "# param_grid = {\n",
    "#     'max_depth': [1, 3, 5],\n",
    "#     'learning_rate': [.05, .1, .15], \n",
    "#     'subsample': [.7, .8, .9],\n",
    "#     'colsample_bytree': np.linspace(.1, 1, 10),\n",
    "#     'min_child_weight': [10, 20, 30], \n",
    "#     'n_estimators': [10, 100, 500]\n",
    "# }\n",
    "# gs_xgb = GridSearchCV(clf_xgb, param_grid, scoring='recall', cv=5)\n",
    "# gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "# test_recalls['XGBoost'] = recall_score(y_test, gs_xgb.predict(X_test))\n",
    "# test_accuracies['XGBoost'] = accuracy_score(y_test, gs_xgb.predict(X_test))\n",
    "\n",
    "# print(f'Train Recall: {gs_xgb.best_score_}')\n",
    "# print(f'Test Recall: {test_recalls[\"XGBoost\"]}')\n",
    "# print(f'Train Accuracy: {accuracy_score(y_train, gs_xgb.predict(X_train))}')\n",
    "# print(f'Test Accuracy: {test_accuracies[\"XGBoost\"]}')\n",
    "# print(gs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models['xgb']=gs_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n",
      "Logistic Regression    0.885714\n",
      "RBF SVC                0.885714\n",
      "Linear SVC             0.885714\n",
      "AdaBoost               0.857143\n",
      "Random Forest          0.857143\n",
      "Decision Tree          0.857143\n",
      "Sigmoid SVC            0.857143\n",
      "Polynomial SVC         0.857143\n",
      "KNN                    0.828571\n",
      "dtype: float64\n",
      "\n",
      "Accuracy\n",
      "Sigmoid SVC            0.880000\n",
      "Logistic Regression    0.853333\n",
      "Decision Tree          0.853333\n",
      "Linear SVC             0.853333\n",
      "AdaBoost               0.840000\n",
      "Random Forest          0.840000\n",
      "KNN                    0.840000\n",
      "RBF SVC                0.826667\n",
      "Polynomial SVC         0.813333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_recalls['Logistic Regression'] = baseline_recall['LogReg']\n",
    "test_accuracies['Logistic Regression'] = baseline_acc['LogReg']\n",
    "print('Recall')\n",
    "print(pd.Series(test_recalls).sort_values(ascending=False))\n",
    "print('')\n",
    "print('Accuracy')\n",
    "print(pd.Series(test_accuracies).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_models:\n",
    "    with open(f'../models/{model}.pkl', 'wb') as fp:\n",
    "        pickle.dump(best_models[model], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I selected the three top performing models: the sigmoid kernel from the SVCs, AdaBoost from the boosters, and the decision tree over the random forest, for a total of **3 individual models**. I combined them into a single voting classifier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142857"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_votehard = VotingClassifier(\n",
    "    estimators=[('svcl', gs_svcl.best_estimator_),\n",
    "                ('lr', LogisticRegressionCV(random_state=42)), \n",
    "                ('ab', gs_ab.best_estimator_)],\n",
    "    voting='soft')\n",
    "clf_votehard.fit(X_train, y_train)\n",
    "recall_score(y_test, clf_votehard.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  7],\n",
       "       [ 4, 31]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf_votehard.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensemble method does as well as two of the individual models, the decision tree and AdaBoost, but not as well the sigmoid SVC. I tried the same model, but with a soft voting system, giving a little more weight to the sigmoid SVC as it performed best on its own. I also included the KNN model hoping the extra diversity in models might produce a more powerful ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_votesoft = VotingClassifier(\n",
    "    estimators=[('knn', gs_knn.best_estimator_),\n",
    "                ('svcs', gs_svcs.best_estimator_), \n",
    "                ('dt', gs_dt.best_estimator_), \n",
    "                ('ab', gs_ab.best_estimator_), \n",
    "                ('lr', LogisticRegressionCV(random_state=42))],\n",
    "    voting='soft')\n",
    "clf_votesoft.fit(X_train, y_train)\n",
    "recall_score(y_test, clf_votesoft.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  7],\n",
       "       [ 5, 30]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf_votesoft.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the model performs as well as the decision tree and AdaBoost each do alone, making this a none too impressive model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7461904761904761\n",
      "Test Recall: 0.8857142857142857\n",
      "Train Accuracy: 0.8288288288288288\n",
      "Test Accuracy: 0.8533333333333334\n",
      "{'ab__base_estimator': DecisionTreeClassifier(max_depth=1), 'ab__learning_rate': 0.01, 'ab__n_estimators': 1000, 'svcl__C': 0.30000000000000004, 'svcl__gamma': 'scale', 'svcl__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'ab__base_estimator': [DecisionTreeClassifier(max_depth=1), LogisticRegression(solver='lbfgs', multi_class='auto')], \n",
    "    'ab__n_estimators': [10, 30, 50, 1000], \n",
    "    'ab__learning_rate': [.0001, .001, .01, .1],\n",
    "    'svcl__kernel': ['linear'], \n",
    "    'svcl__C': np.linspace(.1, 1, 10), \n",
    "    'svcl__gamma': ['scale', 'auto'] \n",
    "}\n",
    "gs_hard = GridSearchCV(clf_votehard, param_grid, scoring='recall', cv=5)\n",
    "gs_hard.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train Recall: {gs_hard.best_score_}')\n",
    "print(f'Test Recall: {recall_score(y_test, gs_hard.predict(X_test))}')\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, gs_hard.predict(X_train))}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, gs_hard.predict(X_test))}')\n",
    "print(gs_hard.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here I tried a lot of different weight combos in a soft vote classifier \n",
    "with 4 of the best performing models, but wasn't able to beat the 87%-89% accuracy\n",
    "above. Already the algorithm is time consuming, and it is inelegant, so I have\n",
    "commented it out. Possibly future work.\n",
    "'''\n",
    "\n",
    "# w = [0, 1, 2, 3]\n",
    "# combos = []\n",
    "# scores = []\n",
    "# for a in w:\n",
    "#     for b in w:\n",
    "#         for c in w:\n",
    "#             for d in w:\n",
    "#                 if a==0 and b==0 and c==0 and d==0: \n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     clf_votesoft = VotingClassifier(\n",
    "#                         estimators=[('lr', baseline_classifiers['LogReg']), \n",
    "#                                     ('svcs', gs_svcs.best_estimator_),\n",
    "#                                     ('dt', gs_dt.best_estimator_), \n",
    "#                                     ('ab', gs_ab.best_estimator_)],\n",
    "#                         voting='soft', \n",
    "#                         weights=[a, b, c, d])\n",
    "#                     clf_votesoft.fit(X_train, y_train)\n",
    "#                     combos.append([a, b, c, d])\n",
    "#                     scores.append(accuracy_score(y_test, clf_votesoft.predict(X_test)))\n",
    "# df = pd.DataFrame([combos, scores]).T\n",
    "# df.columns = ['combos', 'accuracy']\n",
    "# df.sort_values(by='combos', ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There was little preprocessing necessary for this project as the [dataset](https://www.kaggle.com/danimal/heartdiseaseensembleclassifier) was already quite clean. I used a **heatmap of Pearson correlation coefficients** to identify correlated features (which I dropped) and used **feature importance** from a Random Forest to select the 7 most important features of the original 13. Lastly, I **standardized** all features. \n",
    "\n",
    "\n",
    "2. After tuning, accuracy on test data improved for all models except logistic regression, which lost 2% accuracy:\n",
    "\n",
    "| Model | Initial Test Accuracy | Final Test Accuracy |\n",
    "|-|-|-|\n",
    "| Ensemble Classifier (Soft, Unprocessed) | -- | **89%** |\n",
    "| Sigmoid SVC | 55% | **88%** |\n",
    "| AdaBoost | 72% | **87%** |\n",
    "| Decision Tree | 77% | **87%** |\n",
    "| Ensemble Classifier (Soft) | -- | **87%** |\n",
    "| Ensemble Classifier (Hard) | -- | **87%** |\n",
    "| Logistic Regression | 87% | **85%** |\n",
    "| Random Forest | 83% | **85%** |\n",
    "| XGBoost | 81% | **84%** |\n",
    "| KNN | 59% | **82%** |\n",
    "\n",
    "\n",
    "3. On the preprocessed, feature-selected data, hard- and soft-vote ensemble classifiers both achieved 87% accuracy on test data. The hard-vote ensemble consisted of a sigmoid SVC, a decision tree, and an AdaBoost classifier; the soft-vote classifier additionally included a KNN classifier.\n",
    "\n",
    "\n",
    "4. **The model with the highest accuracy on test data (89%) was a soft-vote ensemble classifier using a sigmoid SVC, a decision tree, an AdaBoost classifier, a KNN classifier, and a logistic regression classifier. It was only able to achieve this accuracy on data *that had not undergone dimensionality reduction or standardization* (but had been cleaned of missing values).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
